#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Preparing the data and displaying it to the user (more than 5 products)
# Sources for shortlisting products (best selling PCs in 2017)
# * https://www.foxbusiness.com/markets/best-selling-pcs-of-2017
# * https://finance.yahoo.com/news/best-selling-pcs-2017-230300126.html
# The price and quantity for each product is hypothetical but looks real,
# fulfilling the requirements for the assignment
# Data is initialized using vectors
products <- c('HP 8300 Elite Small Form Factor Desktop Computer', 'HP 22-b016 All-in-One desktop', 'HP Pavilion Power 580-023w Gaming Tower', 'Aspire E 15-inch notebook', 'HP 14 Inch "Stream" Laptop', 'Dell OptiPlex, Intel Core 2 Duo')
price <- c(500, 450, 750, 600, 220, 480)
quantity_2017 <- c(150000, 120000, 100000, 180000, 200000, 110000)
# Displaying the data using a for loop
# Also computing the average price of all products within the loop to
# avoid using another for loop - less computationally intensive
cat("Initialized Product Data (2017):\n")
sumproducts <- 0
for (i in 1:length(products)) {
cat(sprintf('Product = %s; Price ($) = %.2f; Quantity = %d\n', products[i], price[i], quantity_2017[i]))
sumproducts <- sumproducts + price[i]
}
# Calculating and displaying the average price of all products, using the total sum of all prices divided by the number of products
avgPriceAllProducts <- sumproducts / length(products)
cat(sprintf('\nThis is the average price of all products ($) = %.3f\n', avgPriceAllProducts))
# Finding how many products were sold at a price above the average price (use
# a for loop)
# Also finding the total transactions above average price within this for
# loop instead of using another one - less computationally intensive
aboveAvgCount <- 0
TotalTransactionAboveAvg <- 0
for (i in 1:length(price)) {
if (price[i] > avgPriceAllProducts) {
aboveAvgCount <- aboveAvgCount + 1
TotalTransactionAboveAvg <- TotalTransactionAboveAvg + (price[i] * quantity_2017[i])
}
}
cat(sprintf('\nNumber of Products Sold Above Average Price: %d\n', aboveAvgCount))
cat(sprintf('\nTotal Income from Above Average Price Sales ($): %f\n\n', TotalTransactionAboveAvg))
# Finding the total income from each product (use a for loop)
# Computing the total income generated from All Sales within the loop to
# avoid using another loop - less computationally intensive
cat('Total income from each product:\n')
totalIncomeAll <- 0
for (i in 1:length(products)) {
income <- price[i] * quantity_2017[i]
cat(sprintf('%s: %f\n', products[i], income))
totalIncomeAll <- totalIncomeAll + income
}
# Displaying the total income generated from all sales, summed up in the previous loop
cat(sprintf('\nTotal Income from All Sales ($): %f\n', totalIncomeAll))
# Debug step to check if total income from All Sales is correct
# Debug step to check if total income from All Sales is correct
#cat(sum(price * quantity_2017))
# Debug step to check if total income from All Sales is correct
cat(sum(price * quantity_2017))
# Loading necessary libraries
library(readr)
library(dplyr)
library(fastDummies) # This library is used for one-hot encoding in ML Applications
# Loading user-defined functions from separate files (Sourcing)
source('filterOutliers.R')
source('summarizeDataset.R')
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Lab5_R_DataProcessing")
# Loading necessary libraries
library(readr)
library(dplyr)
library(fastDummies) # This library is used for one-hot encoding in ML Applications
# Loading user-defined functions from separate files (Sourcing)
source('filterOutliers.R')
source('summarizeDataset.R')
source('onehotEncoding.R')
source('featureEngineering.R')
# Importing data from local machine
data_filepath <- "diabetes_prediction_dataset.csv"
diabetes_data <- read_csv(data_filepath)
# Analyzing dataset, checking if it has any missing values and analyzing categorical variables
summarizeDataset(diabetes_data)
# Filtering outliers
diabetes_data <- filter_outliers(diabetes_data, "bmi")
# Applying one-hot encoding to categorical variables
# This will generate numerical columns for the Random Forest Ensemble model to interpret
diabetes_data <- onehotEncoding(diabetes_data,
exclude_col = "smoking_history",
exclude_value = "ever",
columns_to_encode = c("gender", "smoking_history"))
# Feature Engineering
diabetes_data <- featureEngineering(diabetes_data)
# Exporting the processed dataset as CSV
export_filepath <- "new_diabetes_dataset.csv"
write_csv(diabetes_data, export_filepath)
clc
clear
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Project2_R")
# Libarary for data manipulation and visualization
library(tideverse)
# Libarary for data manipulation and visualization
library(tidyverse)
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Project2_R")
diabetes_df <- read_csv("new_diabetes_dataset.csv")
# Exploring the Dataset
str(diabetes_df)
summary(diabetes_df)
head(diabetes_df)
# Check for missing values
colSums(is.na(diabetes_df))
# Task 2 and
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
# Loop through each numerical column and create a histogram with KDE
for (col_name in numerical_columns) {
# Print the column name to keep track of the plots
print(col_name)
# Create the plot
plot <- ggplot(diabetes_df, aes_string(x = col_name)) +
geom_histogram(aes(y = ..density..), binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
geom_density(alpha = .2, fill = "red") +
labs(title = paste(col_name, "Distribution with KDE"), x = col_name, y = "Density") +
theme_minimal()
# Print the plot
print(plot)
}
library(ggplot2)
library(ggplot)
package(ggplot)
library(ggplot2)
# Task 2 and
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
# Loop through each numerical column and create a histogram with KDE
for (col_name in numerical_columns) {
# Print the column name to keep track of the plots
print(col_name)
# Create the plot
plot <- ggplot(diabetes_df, aes_string(x = col_name)) +
geom_histogram(aes(y = ..density..), binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
geom_density(alpha = .2, fill = "red") +
labs(title = paste(col_name, "Distribution with KDE"), x = col_name, y = "Density") +
theme_minimal()
# Print the plot
print(plot)
}
# Loop through each numerical column and create a histogram with KDE
for (col_name in numerical_columns) {
# Printing the column name to keep track of the plots
print(col_name)
# Creating the plot
plot <- ggplot(diabetes_df, aes_string(x = col_name)) +
geom_histogram(aes(y = ..density..), binwidth = 5, fill = "blue", color = "black", alpha = 0.7) +
geom_density(alpha = .2, fill = "red") +
labs(title = paste(col_name, "Distribution with KDE"), x = col_name, y = "Density") +
theme_minimal()
# Printing the plot
print(plot)
}
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
# Loop through each numerical column and create a histogram with KDE
for (col_name in numerical_columns) {
# Printing the column name to keep track of the plots
print(col_name)
# Creating the plot
plot <- ggplot(diabetes_df, aes_string(x = col_name)) +
geom_histogram(aes(y = ..density..), binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
geom_density(alpha = .2, fill = "red") +
labs(title = paste(col_name, "Distribution with KDE"), x = col_name, y = "Density") +
theme_minimal()
# Printing the plot
print(plot)
}
diabetes_df <- diabetes_df %>%
mutate(diabetes_risk_score = (0.5 * age) +
(2 * bmi) +
(1.5 * hypertension) +
(2 * heart_disease) +
(0.75 * blood_glucose_level))
# Making sure new column was created
colnames(diabetes_df)
# **Task 6 (applying some functions on data)**
# Purpose of performing task 6:
# - Normalize the age and bmi columns to ensure that these features are on a similar scale
# - This is useful for distance-based algorithms in ML as it prevents variables with
# larger ranges from dominating those with smaller ranges
# Apply Functions on Data - Normalizing age and bmi
# Normalize function scales the data between 0 and 1
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
# Normalizing 'age' and 'bmi' columns
diabetes_df <- diabetes_df %>%
mutate(age_normalized = normalize(age),
bmi_normalized = normalize(bmi))
# Ensuring the new columns were created correctly
colnames(diabetes_df)
# **Task 9: Binning**
# Purpose of performing task 9:
# - This will categorize age into different groups
# - This could help in understanding the distribution of diabetes across different age groups
diabetes_df$age_group <- cut(diabetes_df$age,
breaks = c(0, 18, 30, 45, 60, 75, Inf),
labels = c("0-18", "19-30", "31-45", "46-60", "61-75", "76+"),
include.lowest = TRUE)
# Viewing the distribution of age groups
table(diabetes_df$age_group)
# **Task 11 (Sampling)**
# Purpose of performing task 11:
# - We will create a sample of the dataset to test models
# - Useful in handling large datasets by reducing the computational load for model training
# Creating a sample of 1000 entries for inital model testing
set.seed(317) # Ensure reproducibility
sampled_df <- sample_n(diabetes_df, 1000)
# **Task 12 (Counting)**
# Purpose of performing task 12:
# - We'll count the number of individuals with and without diabetes
# - Useful for checking if the dataset is imbalanced or not
# Counting the number of individuals with and without diabetes
diabetes_counts <- table(diabetes_df$diabetes)
print(diabetes_counts)
# Ensuring the age_group column was created correctly and viewing the first few rows
head(diabetes_df)
# Printing the structure of the sampled data
str(sampled_df)
# Make sure to set your own working directory
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Project2_R")
# Loading libraries
library(readr)
library(dplyr)
library(ggplot2)
diabetes_df <- read_csv("new_diabetes_dataset.csv")
# Exploring the Dataset
str(diabetes_df)
summary(diabetes_df)
head(diabetes_df)
# Check for missing values
colSums(is.na(diabetes_df))
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
# Loop through each numerical column and create a histogram with KDE
for (col_name in numerical_columns) {
# Printing the column name to keep track of the plots
print(col_name)
# Creating the plot
plot <- ggplot(diabetes_df, aes_string(x = col_name)) +
geom_histogram(aes(y = ..density..), binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
geom_density(alpha = .2, fill = "red") +
labs(title = paste(col_name, "Distribution with KDE"), x = col_name, y = "Density") +
theme_minimal()
# Printing the plot
print(plot)
}
diabetes_df <- diabetes_df %>%
mutate(diabetes_risk_score = (0.5 * age) +
(2 * bmi) +
(1.5 * hypertension) +
(2 * heart_disease) +
(0.75 * blood_glucose_level))
# Making sure new column was created
colnames(diabetes_df)
# **Task 6 (applying some functions on data)**
# Purpose of performing task 6:
# - Normalize the age and bmi columns to ensure that these features are on a similar scale
# - This is useful for distance-based algorithms in ML as it prevents variables with
# larger ranges from dominating those with smaller ranges
# Apply Functions on Data - Normalizing age and bmi
# Normalize function scales the data between 0 and 1
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
# Normalizing 'age' and 'bmi' columns
diabetes_df <- diabetes_df %>%
mutate(age_normalized = normalize(age),
bmi_normalized = normalize(bmi))
# Ensuring the new columns were created correctly
colnames(diabetes_df)
# Binning age into categories
diabetes_df$age_group <- cut(diabetes_df$age,
breaks = c(0, 18, 30, 45, 60, 75, Inf),
labels = c("0-18", "19-30", "31-45", "46-60", "61-75", "76+"),
include.lowest = TRUE)
# Viewing the distribution of age groups
table(diabetes_df$age_group)
# **Task 12 (Sampling)**
# Purpose of performing task 12:
# - We will create a sample of the dataset to test models
# - Useful in handling large datasets by reducing the computational load for model training
# Creating a sample of 1000 entries for inital model testing
set.seed(317) # Ensure reproducibility
sampled_df <- sample_n(diabetes_df, 1000)
# **Task 13 (Counting)**
# Purpose of performing task 13:
# - We'll count the number of individuals with and without diabetes
# - Useful for checking if the dataset is imbalanced or not
# Counting the number of individuals with and without diabetes
diabetes_counts <- table(diabetes_df$diabetes)
print(diabetes_counts)
# Ensuring the age_group column was created correctly and viewing the first few rows
head(diabetes_df)
# Printing the structure of the sampled data
str(sampled_df)
# Exporting the full modified dataset
write_csv(diabetes_df, "modified_diabetes_dataset.csv")
# Exporting the sampled dataset
write_csv(sampled_df, "sampled_diabetes_dataset.csv")
# Make sure to set your own working directory
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Project2_R")
# Loading libraries
library(readr)
library(dplyr)
library(ggplot2)
diabetes_df <- read_csv("new_diabetes_dataset.csv")
# Exploring the Dataset
str(diabetes_df)
summary(diabetes_df)
head(diabetes_df)
# Check for missing values
colSums(is.na(diabetes_df))
# Task 2 and 11
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
visualize_numerical_columns(diabetes_df, numerical_columns)
# Make sure to set your own working directory
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Project2_R")
# Loading libraries
library(readr)
library(dplyr)
library(ggplot2)
# Loading functions
source("task2_11.R")
source("task3_4.R")
diabetes_df <- read_csv("new_diabetes_dataset.csv")
# Exploring the Dataset
str(diabetes_df)
summary(diabetes_df)
head(diabetes_df)
# Check for missing values
colSums(is.na(diabetes_df))
# Task 2 and 11
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
visualize_numerical_columns(diabetes_df, numerical_columns)
# Task 3 & 4
diabetes_df <- add_diabetes_risk_score(diabetes_df)
# Making sure new column was created
colnames(diabetes_df)
# **Task 6 (applying some functions on data)**
# Purpose of performing task 6:
# - Normalize the age and bmi columns to ensure that these features are on a similar scale
# - This is useful for distance-based algorithms in ML as it prevents variables with
# larger ranges from dominating those with smaller ranges
# Apply Functions on Data - Normalizing age and bmi
# Normalize function scales the data between 0 and 1
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
# Normalizing 'age' and 'bmi' columns
diabetes_df <- diabetes_df %>%
mutate(age_normalized = normalize(age),
bmi_normalized = normalize(bmi))
# Ensuring the new columns were created correctly
colnames(diabetes_df)
# Binning age into categories
diabetes_df$age_group <- cut(diabetes_df$age,
breaks = c(0, 18, 30, 45, 60, 75, Inf),
labels = c("0-18", "19-30", "31-45", "46-60", "61-75", "76+"),
include.lowest = TRUE)
# Viewing the distribution of age groups
table(diabetes_df$age_group)
# **Task 12 (Sampling)**
# Purpose of performing task 12:
# - We will create a sample of the dataset to test models
# - Useful in handling large datasets by reducing the computational load for model training
# Creating a sample of 1000 entries for inital model testing
set.seed(317) # Ensure reproducibility
sampled_df <- sample_n(diabetes_df, 1000)
# **Task 13 (Counting)**
# Purpose of performing task 13:
# - We'll count the number of individuals with and without diabetes
# - Useful for checking if the dataset is imbalanced or not
# Counting the number of individuals with and without diabetes
diabetes_counts <- table(diabetes_df$diabetes)
print(diabetes_counts)
# Ensuring the age_group column was created correctly and viewing the first few rows
head(diabetes_df)
# Printing the structure of the sampled data
str(sampled_df)
# **Task 5 (Change Column Types)**
# Purpose of performing task 5:
# - facilitates certain types of analysis or visualization that work better with categorical data
# Changing 'diabetes' from numeric to factor
diabetes_df$diabetes <- as.factor(diabetes_df$diabetes)
# Exporting the full modified dataset
write_csv(diabetes_df, "modified_diabetes_dataset.csv")
# Exporting the sampled dataset
write_csv(sampled_df, "sampled_diabetes_dataset.csv")
# Exporting the full modified dataset
write_csv(diabetes_df, "modified_diabetes_dataset.csv")
# Exporting the sampled dataset
write_csv(sampled_df, "sampled_diabetes_dataset.csv")
# Make sure to set your own working directory
setwd("~/Desktop/CSCI-317_Computation-for-Scientific-Applications_Project-And-Labs/Project2_R")
# Loading libraries (Note to grader: please make sure packages are installed)
library(readr)
library(dplyr)
library(ggplot2)
# Loading functions
source("task2_11.R")
source("task3_4.R")
diabetes_df <- read_csv("new_diabetes_dataset.csv")
# Exploring the Dataset
str(diabetes_df)
summary(diabetes_df)
head(diabetes_df)
# Check for missing values
colSums(is.na(diabetes_df))
# Task 2 and 11
# List of numerical columns for which we want to create histograms with KDE
numerical_columns <- c("age", "hypertension", "heart_disease", "bmi", "HbA1c_level", "blood_glucose_level", "diabetes")
visualize_numerical_columns(diabetes_df, numerical_columns)
# Task 3 & 4
diabetes_df <- add_diabetes_risk_score(diabetes_df)
# Making sure new column was created
colnames(diabetes_df)
# **Task 6 (applying some functions on data)**
# Purpose of performing task 6:
# - Normalize the age and bmi columns to ensure that these features are on a similar scale
# - This is useful for distance-based algorithms in ML as it prevents variables with
# larger ranges from dominating those with smaller ranges
# Apply Functions on Data - Normalizing age and bmi
# Normalize function scales the data between 0 and 1
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
# Normalizing 'age' and 'bmi' columns
diabetes_df <- diabetes_df %>%
mutate(age_normalized = normalize(age),
bmi_normalized = normalize(bmi))
# Ensuring the new columns were created correctly
colnames(diabetes_df)
# Binning age into categories
diabetes_df$age_group <- cut(diabetes_df$age,
breaks = c(0, 18, 30, 45, 60, 75, Inf),
labels = c("0-18", "19-30", "31-45", "46-60", "61-75", "76+"),
include.lowest = TRUE)
# Viewing the distribution of age groups
table(diabetes_df$age_group)
# **Task 12 (Sampling)**
# Purpose of performing task 12:
# - We will create a sample of the dataset to test models
# - Useful in handling large datasets by reducing the computational load for model training
# Creating a sample of 1000 entries for inital model testing
set.seed(317) # Ensure reproducibility
sampled_df <- sample_n(diabetes_df, 1000)
# **Task 13 (Counting)**
# Purpose of performing task 13:
# - We'll count the number of individuals with and without diabetes
# - Useful for checking if the dataset is imbalanced or not
# Counting the number of individuals with and without diabetes
diabetes_counts <- table(diabetes_df$diabetes)
print(diabetes_counts)
# Ensuring the age_group column was created correctly and viewing the first few rows
head(diabetes_df)
# Printing the structure of the sampled data
str(sampled_df)
# **Task 5 (Change Column Types)**
# Purpose of performing task 5:
# - facilitates certain types of analysis or visualization that work better with categorical data
# Changing 'diabetes' from numeric to factor
diabetes_df$diabetes <- as.factor(diabetes_df$diabetes)
# Exporting the full modified dataset
write_csv(diabetes_df, "modified_diabetes_dataset.csv")
